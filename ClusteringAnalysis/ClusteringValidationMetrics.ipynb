{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original code from **[here](https://github.com/intelligent-environments-lab/ProfileClustering)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-21T11:50:17.838502Z",
     "start_time": "2018-12-21T11:50:17.834435Z"
    }
   },
   "outputs": [],
   "source": [
    "# Built-in libraries\n",
    "import time\n",
    "from itertools import product\n",
    "from math import log\n",
    "import pickle\n",
    "\n",
    "# NumPy, SciPy and Pandas\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-21T11:50:18.225462Z",
     "start_time": "2018-12-21T11:50:18.209275Z"
    }
   },
   "outputs": [],
   "source": [
    "def divide(data, labels):\n",
    "    clusters = set(labels)\n",
    "    clusters_data = []\n",
    "    for cluster in clusters:\n",
    "        clusters_data.append(data[labels == cluster, :])\n",
    "    return clusters_data\n",
    "\n",
    "def get_centroids(clusters):\n",
    "    centroids = []\n",
    "    for cluster_data in clusters:\n",
    "        centroids.append(cluster_data.mean(axis=0))\n",
    "    return centroids\n",
    "\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import calinski_harabaz_score\n",
    "\n",
    "def get_validation_scores(data, labels):\n",
    "    within_cluster_dist_sum_store.clear()\n",
    "    \n",
    "    clusters = divide(data, labels)\n",
    "    centroids = get_centroids(clusters)\n",
    "    \n",
    "    scores = {}\n",
    "\n",
    "    scores['cohesion'] = cohesion(data, labels)\n",
    "    scores['separation'] = separation(data, labels, scores['cohesion'])\n",
    "    scores['calinski_harabaz_score'] = calinski_harabaz_score(data, labels)\n",
    "    scores['RMSSTD'] = RMSSTD(data, clusters, centroids)\n",
    "    scores['RS'] = RS(data, clusters, centroids)\n",
    "    scores['DB'] = DB(data, clusters, centroids)\n",
    "    scores['XB'] = XB(data, clusters, centroids)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def cohesion(data, labels):\n",
    "    clusters = sorted(set(labels))\n",
    "    sse = 0\n",
    "    for cluster in clusters:\n",
    "        cluster_data = data[labels == cluster, :]\n",
    "        centroid = cluster_data.mean(axis = 0)\n",
    "        sse += ((cluster_data - centroid)**2).sum()\n",
    "    return sse\n",
    "\n",
    "def separation(data, labels, cohesion_score):\n",
    "    # calculate separation as SST - SSE\n",
    "    return cohesion(data, np.zeros(data.shape[0])) - cohesion_score\n",
    "\n",
    "def SST(data):\n",
    "    c = get_centroids([data])\n",
    "    return ((data - c) ** 2).sum()\n",
    "\n",
    "def SSE(clusters, centroids):\n",
    "    result = 0\n",
    "    for cluster, centroid in zip(clusters, centroids):\n",
    "        result += ((cluster - centroid) ** 2).sum()\n",
    "    return result\n",
    "\n",
    "# Clear the store before running each time\n",
    "within_cluster_dist_sum_store = {}\n",
    "def within_cluster_dist_sum(cluster, centroid, cluster_id):\n",
    "    if cluster_id in within_cluster_dist_sum_store:\n",
    "        return within_cluster_dist_sum_store[cluster_id]\n",
    "    else:\n",
    "        result = (((cluster - centroid) ** 2).sum(axis=1)**.5).sum()\n",
    "        within_cluster_dist_sum_store[cluster_id] = result\n",
    "    return result\n",
    "\n",
    "def RMSSTD(data, clusters, centroids):\n",
    "    df = data.shape[0] - len(clusters)\n",
    "    attribute_num = data.shape[1]\n",
    "    return (SSE(clusters, centroids) / (attribute_num * df)) ** .5\n",
    "\n",
    "# equal to separation / (cohesion + separation)\n",
    "def RS(data, clusters, centroids):\n",
    "    sst = SST(data)\n",
    "    sse = SSE(clusters, centroids)\n",
    "    return (sst - sse) / sst\n",
    "\n",
    "def DB_find_max_j(clusters, centroids, i):\n",
    "    max_val = 0\n",
    "    max_j = 0\n",
    "    for j in range(len(clusters)):\n",
    "        if j == i:\n",
    "            continue\n",
    "        cluster_i_stat = within_cluster_dist_sum(clusters[i], centroids[i], i) / clusters[i].shape[0]\n",
    "        cluster_j_stat = within_cluster_dist_sum(clusters[j], centroids[j], j) / clusters[j].shape[0]\n",
    "        val = (cluster_i_stat + cluster_j_stat) / (((centroids[i] - centroids[j]) ** 2).sum() ** .5)\n",
    "        if val > max_val:\n",
    "            max_val = val\n",
    "            max_j = j\n",
    "    return max_val\n",
    "\n",
    "def DB(data, clusters, centroids):\n",
    "    result = 0\n",
    "    for i in range(len(clusters)):\n",
    "        result += DB_find_max_j(clusters, centroids, i)\n",
    "    return result / len(clusters)\n",
    "\n",
    "def XB(data, clusters, centroids):\n",
    "    sse = SSE(clusters, centroids)\n",
    "    min_dist = ((centroids[0] - centroids[1]) ** 2).sum()\n",
    "    for centroid_i, centroid_j in list(product(centroids, centroids)):\n",
    "        if (centroid_i - centroid_j).sum() == 0:\n",
    "            continue\n",
    "        dist = ((centroid_i - centroid_j) ** 2).sum()\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "    return sse / (data.shape[0] * min_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-21T11:50:20.846257Z",
     "start_time": "2018-12-21T11:50:20.842756Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: change parameters and add description\n",
    "def combineMetrics(data, rangeK):\n",
    "    dict_metrics_all = {}\n",
    "    # since all the keys are the same. Each metric is a different key\n",
    "    for metric in data[0].keys():\n",
    "        # add the values for each key\n",
    "        dict_metrics_all[metric] = tuple(dict_metrics_all[metric] for dict_metrics_all in data)\n",
    "    return dict_metrics_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
