{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-21T11:57:03.237939Z",
     "start_time": "2018-12-21T11:57:03.235541Z"
    }
   },
   "source": [
    "# This notebook will be the only interaction with all any experiment notebook. From here the function calls to all the preprocessing and clustering notebooks will be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-23T10:17:45.561980Z",
     "start_time": "2018-12-23T10:17:45.559252Z"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries needed\n",
    "# !pip install nbimporter # uncomment if library is not install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-23T10:17:48.096173Z",
     "start_time": "2018-12-23T10:17:45.563997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from /Users/matias/Documents/Education/Graduate/NUS/Projects/sensor-cluster-er/Preprocessing/preprocessing.ipynb\n",
      "Importing Jupyter notebook from /Users/matias/Documents/Education/Graduate/NUS/Projects/sensor-cluster-er/Preprocessing/context_extraction.ipynb\n",
      "Importing Jupyter notebook from /Users/matias/Documents/Education/Graduate/NUS/Projects/sensor-cluster-er/Preprocessing/load_cuve_generation.ipynb\n",
      "Importing Jupyter notebook from /Users/matias/Documents/Education/Graduate/NUS/Projects/sensor-cluster-er/ClusteringAnalysis/ClusteringValidationMetrics.ipynb\n",
      "Importing Jupyter notebook from /Users/matias/Documents/Education/Graduate/NUS/Projects/sensor-cluster-er/ClusteringAnalysis/Kshape.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Existing Notebooks\n",
    "import nbimporter\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from Preprocessing.preprocessing import hourly_dataset\n",
    "from Preprocessing.context_extraction import getContext\n",
    "from Preprocessing.load_cuve_generation import doAggregation\n",
    "\n",
    "from ClusteringAnalysis.ClusteringValidationMetrics import get_validation_scores, combineMetrics\n",
    "from ClusteringAnalysis.Kshape import doKshape\n",
    "\n",
    "# Built-in libraries\n",
    "import time\n",
    "from itertools import product\n",
    "from math import log\n",
    "import pickle\n",
    "\n",
    "# NumPy, SciPy and Pandas\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-23T11:01:20.315851Z",
     "start_time": "2018-12-23T11:01:20.307773Z"
    }
   },
   "outputs": [],
   "source": [
    "# check files\n",
    "def checkFiles(datasetName, context, function):\n",
    "    # if the dataset is the combination, directly load the aggregated dataset for the datasets\n",
    "    if datasetName == 'BDG-DGS':\n",
    "        df1_name = 'BDG'\n",
    "        df2_name = 'DGS'\n",
    "\n",
    "        df1 = pd.read_csv('../data/processed/{}_{}_{}_dataset.csv'.format(df1_name, context, function), index_col=0)\n",
    "        df2 = pd.read_csv('../data/processed/{}_{}_{}_dataset.csv'.format(df2_name, context, function), index_col=0)\n",
    "    \n",
    "        df = df1.append(df2)\n",
    "        df.to_csv('../data/processed/{}_{}_{}_dataset.csv'.format(datasetName, context, function))\n",
    "    else:\n",
    "        # check if dataset has already being processed before\n",
    "        exists_df = os.path.isfile('../data/processed/{}_dataset.csv'.format(datasetName))\n",
    "        if exists_df: # if file exists, read it\n",
    "            df = pd.read_csv('../data/processed/{}_dataset.csv'.format(datasetName), index_col=0)\n",
    "            print(\"Preprocessed dataset already exists, loading it ...\")\n",
    "        else: # if file is missing, produce it\n",
    "            df = hourly_dataset(datasetName)\n",
    "            print(\"Preprocessing dataset ...\")\n",
    "\n",
    "        # check if dataset with context has already being processed before\n",
    "        exists_context = os.path.isfile('../data/processed/{}_{}_dataset.csv'.format(datasetName, context))\n",
    "        if exists_context: # if file exists, read it\n",
    "            df = pd.read_csv('../data/processed/{}_{}_dataset.csv'.format(datasetName, context), index_col=0)\n",
    "            print(\"Dataset with {} context already exists, loading it ...\".format(context))\n",
    "        else: # if file is missing, produce it\n",
    "            df = getContext(datasetName, context)\n",
    "            print(\"Generating context dataset ...\")\n",
    "\n",
    "        # check if dataset with function has already being processed before\n",
    "        exists_function = os.path.isfile('../data/processed/{}_{}_{}_dataset.csv'.format(datasetName, context, function))\n",
    "        if exists_function: # if file exists, read it\n",
    "            df = pd.read_csv('../data/processed/{}_{}_{}_dataset.csv'.format(datasetName, context, function), index_col=0)\n",
    "            print(\"Dataset with {} context and {} load curve aggregation function already exists, loading it ...\".format(context, function))\n",
    "\n",
    "        else: # if file is missing, produce it\n",
    "            df = doAggregation(datasetName, context, function)\n",
    "            print(\"Generating load curves based on {} ...\".format(function))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-23T11:58:28.592369Z",
     "start_time": "2018-12-23T11:58:28.582875Z"
    }
   },
   "outputs": [],
   "source": [
    "# Running Experiment \n",
    "def runExperiment(datasetName, context, function, algorithm='kshape', \n",
    "                  algo_parameter=range(2,11), validation_metrics='all', appendTotalFile=False):\n",
    "    # check if file exists and load it\n",
    "    df = checkFiles(datasetName, context, function)\n",
    "    \n",
    "    scores = [] # list of the scores for each parameter for the selected algorithm\n",
    "    \n",
    "    # run selected algorithm with the appropiate parameter\n",
    "    if algorithm == 'kshape':\n",
    "        # run kshape for each value of K\n",
    "        for k in algo_parameter:\n",
    "            model, labels = doKshape(df, datasetName, k, seed=3, max_iter=200)\n",
    "            scores.append(get_validation_scores(df.values, labels))\n",
    "            print(\"Running experiment with {} and k = {}\".format(algorithm, k))\n",
    "   \n",
    "    # name for saving the results\n",
    "    obj_name = '../data/results/{}_{}_{}_{}_scores'.format(datasetName, context, function, algorithm)\n",
    "    \n",
    "    # update the final score dataframe\n",
    "    scores = pd.DataFrame.from_dict(scores)\n",
    "    scores.insert(0, 'dataset', '')\n",
    "    scores['dataset'] = datasetName\n",
    "    scores.insert(1, 'context', '')\n",
    "    scores['context'] = context\n",
    "    scores.insert(2, 'function', '')\n",
    "    scores['function'] = function\n",
    "    scores.insert(3, 'algorithm', '')\n",
    "    scores['algorithm'] = algorithm\n",
    "    if \"k\" in algorithm:\n",
    "        scores.insert(4, 'parameter k', '')\n",
    "        scores['parameter k'] = algo_parameter\n",
    "        \n",
    "    # save as python pickle\n",
    "    f = open(obj_name + '.pkl', 'wb')\n",
    "    pickle.dump(scores, f)\n",
    "    f.close\n",
    "    \n",
    "    # save as csv\n",
    "    scores.to_csv('{}.csv'.format(obj_name))\n",
    "    print('Scores saved in {}.csv'.format(obj_name)) # individual file\n",
    "    \n",
    "    if appendTotalFile:\n",
    "        with open('../data/results/total_scores.csv', 'a') as f: # append to general file\n",
    "            scores.to_csv(f, header=False)\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-23T10:17:48.118758Z",
     "start_time": "2018-12-23T10:17:48.115255Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generating clusters and centroids\n",
    "def generateClusters(datasetName, context, function, algorithm='kshape', algo_parameter = 5):\n",
    "    # check if file exists and load it\n",
    "    df = checkFiles(datasetName, context, function)\n",
    "    \n",
    "    # run algorithm\n",
    "    if algorithm == 'kshape':\n",
    "        # run kshape with the given k's (can be a list)\n",
    "        for k in algo_parameter:\n",
    "            model, labels = doKshape(df, datasetName, k, seed=3, max_iter=200, plot=True)\n",
    "#             scores.append(get_validation_scores(df.values, labels))\n",
    "            print(\"Running experiment with {} and k = {}\".format(algorithm, k))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-23T10:17:48.127713Z",
     "start_time": "2018-12-23T10:17:48.121401Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualizing Scores\n",
    "def generateMetricPlots(datasetName, context, function, algorithm='kshape', showPlots=False):\n",
    "    plt.ioff() # this way only plt.show() will display figures\n",
    "\n",
    "    pickle_in = open(\"../data/results/{}_{}_{}_{}_scores.pkl\".format(datasetName, context, function, algorithm), \n",
    "                         \"rb\")\n",
    "    df_scores = pickle.load(pickle_in)\n",
    "    pickle_in.close()\n",
    "    \n",
    "    # the x-axis is the different parameter values of the algorith,\n",
    "    if algorithm == 'kshape': # in this case, the parameter is the value of k\n",
    "        x_axis = list(df_scores.iloc[:, 4]) # the column of index 4 is where the parameter is stored\n",
    "    \n",
    "    # dataframe of only the validation metrics\n",
    "    df_metrics = df_scores.iloc[:, range(5, len(df_scores.columns))]\n",
    "    # the total number of metrics available is 7\n",
    "    num_metrics = len(df_metrics.columns) # but we double check just in case\n",
    "    # extract column names for plotting\n",
    "    metric_names = df_metrics.columns.values\n",
    "    metric_index = 0\n",
    "    \n",
    "    # iterate through every metric and plot the value versus the correspondant algo parameter\n",
    "    f, axarr = plt.subplots(num_metrics, sharex=False, figsize =(10,30))\n",
    "    for metric in range(len(df_metrics.columns)):\n",
    "        axarr[metric_index].plot(x_axis, df_metrics.iloc[:, metric], \"k-\")\n",
    "        axarr[metric_index].set_title(\"{} curve over K values\".format(metric_names[metric_index]), fontsize = 18)\n",
    "        metric_index += 1\n",
    "    \n",
    "    # if boolean parameter for plotting is True, show the figure\n",
    "    if showPlots:\n",
    "        plt.show()\n",
    "    \n",
    "    f.savefig(\"../data/plots/{}_{}_{}_{}_plots.png\".format(datasetName, context, function, algorithm), \n",
    "                                                              bbox_inches='tight')\n",
    "    print(\"Plots saved in ../data/plots/{}_{}_{}_{}_plots.png\".format(datasetName, context, function, algorithm))\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
